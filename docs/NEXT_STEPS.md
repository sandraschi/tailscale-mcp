# ğŸš€ Next Steps - Prioritized Action Plan

**Created:** 2025-01-15  
**Based On:** [Repository Assessment](REPOSITORY_ASSESSMENT.md)  
**Status:** Ready to Execute

---

## ğŸ¯ Immediate Priority (This Week)

### **Step 1: Create Operations Layer** âš¡ **CRITICAL**

**Why:** The operations layer bridges the API client and managers. Without it, we can't wire up real API calls properly.

**Estimated Time:** 2-3 days

**Tasks:**

1. **Create operations directory structure**
   ```bash
   mkdir -p src/tailscalemcp/operations
   ```

2. **Create `operations/devices.py`**
   - Implement device CRUD operations using `TailscaleAPIClient`
   - Methods: `list_devices`, `get_device`, `update_device`, `delete_device`, `authorize_device`
   - Wire into `device_management.py`

3. **Create `operations/network.py`**
   - Implement network operations: DNS, policies, MagicDNS
   - Wire into `magic_dns.py`

4. **Create `operations/services.py`**
   - Implement Services (TailVIPs) operations
   - Models already exist in `models/service.py`
   - Client methods already exist in `client/api_client.py`
   - Just need operations layer to wire them together

**Files to Create:**
```
src/tailscalemcp/operations/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ devices.py       # Device CRUD operations
â”œâ”€â”€ network.py       # Network configuration
â”œâ”€â”€ services.py     # Tailscale Services (TailVIPs)
â””â”€â”€ policies.py     # ACL policy management (optional for now)
```

**Success Criteria:**
- [ ] Operations layer created with real API implementations
- [ ] Managers updated to use operations layer
- [ ] No mock data in operations layer

---

### **Step 2: Audit & Remove Mock Data** ğŸ” **CRITICAL**

**Why:** Assessment shows mock data still exists in managers. Need to replace with real API calls.

**Estimated Time:** 1-2 days

**Tasks:**

1. **Audit managers for mock data:**
   - `src/tailscalemcp/device_management.py`
   - `src/tailscalemcp/magic_dns.py`
   - `src/tailscalemcp/monitoring.py`
   - `src/tailscalemcp/taildrop.py`

2. **Replace mocks with operations layer calls**

3. **Test each manager with real API** (use test tailnet)

**Files to Audit:**
```python
# Look for patterns like:
- Hardcoded data: devices = [{"id": "mock1", ...}]
- Simulated responses: return {"status": "simulated"}
- Mock functions: async def get_device(): return mock_data
```

**Success Criteria:**
- [ ] All managers use operations layer
- [ ] No hardcoded mock data
- [ ] All operations make real API calls

---

### **Step 3: Add Critical Unit Tests** ğŸ§ª **HIGH**

**Why:** Test coverage is 24%, target is 80%. Need foundation tests for new components.

**Estimated Time:** 2 days

**Tasks:**

1. **Create test directory structure**
   ```bash
   mkdir -p tests/unit tests/integration
   ```

2. **Unit tests for API client:**
   - `tests/unit/test_client.py` - Rate limiting, retry logic, error handling
   - Mock `httpx.AsyncClient` (not internal functions!)

3. **Unit tests for models:**
   - `tests/unit/test_models.py` - Parsing, validation, serialization

4. **Integration tests for operations:**
   - `tests/integration/test_device_operations.py`
   - `tests/integration/test_services_operations.py`
   - Use mocked API responses

**Files to Create:**
```
tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ test_client.py
â”‚   â”œâ”€â”€ test_rate_limiter.py
â”‚   â”œâ”€â”€ test_retry.py
â”‚   â””â”€â”€ test_models.py
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ test_device_operations.py
â”‚   â””â”€â”€ test_services_operations.py
â””â”€â”€ conftest.py (fixtures)
```

**Success Criteria:**
- [ ] Unit tests for client, models, rate limiter, retry handler
- [ ] Integration tests for operations layer
- [ ] Coverage increases from 24% â†’ 60%+

---

## ğŸ“‹ Short Term (Next 2 Weeks)

### **Step 4: Complete Tailscale Services Integration** âš¡ **QUICK WIN**

**Why:** Models + client methods already exist. Just need operations layer wiring.

**Estimated Time:** 1 day

**Tasks:**
1. Wire `operations/services.py` into `tailscale_network` portmanteau tool
2. Verify all 5 services operations work: list, get, create, update, delete
3. Add integration tests
4. Update documentation

**Success Criteria:**
- [ ] Services operations fully functional
- [ ] Portmanteau tool integration complete
- [ ] Tests passing

---

### **Step 5: Increase Test Coverage** ğŸ“ˆ **HIGH**

**Why:** Target 80% coverage (GLAMA Gold Standard). Current: 24%.

**Estimated Time:** 3-4 days

**Tasks:**
1. Add tests for all operations
2. Add error handling tests
3. Add performance tests (rate limiting, connection pooling)
4. Set up coverage reporting in CI/CD

**Success Criteria:**
- [ ] Coverage reaches 80%
- [ ] All critical paths tested
- [ ] CI/CD reports coverage

---

### **Step 6: Comprehensive Error Handling** ğŸ›¡ï¸ **HIGH**

**Why:** Production readiness requires graceful error handling.

**Estimated Time:** 2 days

**Tasks:**
1. Add graceful degradation patterns
2. Pre-flight validation for destructive operations
3. Better error messages with remediation steps
4. Operation logging and audit trails

**Success Criteria:**
- [ ] All operations have error handling
- [ ] Clear error messages with next steps
- [ ] Audit logging in place

---

## ğŸ¯ Recommended Starting Point

**Start with Step 1: Operations Layer**

This is the foundation that everything else depends on. Once it's in place:
- âœ… Managers can use real API calls
- âœ… Mock data removal becomes straightforward
- âœ… Testing becomes meaningful
- âœ… New features can be added easily

**Suggested Workflow:**
1. Create `operations/devices.py` first (most used)
2. Update `device_management.py` to use it
3. Create `operations/services.py` (quick win)
4. Update portmanteau tools to wire services
5. Then tackle network operations

---

## ğŸ“Š Success Metrics

**Week 1 Goals:**
- [ ] Operations layer created
- [ ] Mock data removed from managers
- [ ] Critical unit tests added
- [ ] Test coverage: 24% â†’ 60%+

**Week 2 Goals:**
- [ ] Services integration complete
- [ ] Test coverage: 60% â†’ 80%
- [ ] Error handling improved
- [ ] Documentation updated

---

## ğŸš¨ Critical Reminders

**From AI Development Rules:**
- âŒ **NEVER** add mock data - use real API calls or clear "not implemented" messages
- âœ… Always mock at HTTP client level (`httpx.AsyncClient`), not internal functions
- âœ… Preserve existing functionality
- âœ… Test with real API (use test tailnet) when possible

---

**Last Updated:** 2025-01-15  
**Next Review:** After Step 1 completion







